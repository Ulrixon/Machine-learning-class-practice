{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% import\n",
    "from copy import deepcopy\n",
    "from itertools import chain, combinations\n",
    "from re import I\n",
    "from statistics import mean\n",
    "from cmath import log\n",
    "from unicodedata import numeric\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "from numpy import argmin, linalg\n",
    "from numpy.linalg import inv\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% import data\n",
    "data1 = pd.read_excel(r\"/Users/ryan/Downloads/data4.xlsx\", sheet_name=0, header=0)\n",
    "xdata1 = data1.iloc[range(300), range(2, 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% c10 取ii list\n",
    "xcombination = []\n",
    "for ii in range(1, 11):\n",
    "    xcombination.append(list(combinations(range(10), ii)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% x分布圖\n",
    "for i in range(10):\n",
    "\n",
    "    plt.hist(xdata1.iloc[:, i])\n",
    "    plt.title(i + 1)\n",
    "    plt.show()\n",
    "plt.hist(xdata1.iloc[:, 9].apply(lambda x: log(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 1 ans:\n",
    "因為x變數在某些x上不是常態,而且qda,lda跑出的\n",
    "最好模型也包含那些非常態變數，所以用logit模型最適合\n",
    "不過我還是都跑跑看，順帶一提變異數也明顯不同且cv值最低的不是logit而是qda。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% LDA+LOOCV\n",
    "ldacvindex = deepcopy(xcombination)\n",
    "for j in range(10):\n",
    "    for k in range(int(len(xcombination[j]))):\n",
    "\n",
    "        X = xdata1.iloc[:, list(map(int, xcombination[j][k]))]\n",
    "        y = data1.loc[::, \"y\"]\n",
    "        CV = 0\n",
    "        # loocv\n",
    "        for l in range(300):\n",
    "            lda = LinearDiscriminantAnalysis()\n",
    "            Xexclude = X.iloc[chain(range(l), range(l + 1, 300)), ::]\n",
    "            yexclude = y[chain(range(l), range(l + 1, 300))]\n",
    "            yout = X.iloc[l, ::]\n",
    "            ypred = lda.fit(Xexclude.values, yexclude.values).predict(\n",
    "                np.reshape(X.loc[l].to_numpy(), (1, j + 1))\n",
    "            )\n",
    "            CV = CV + (y[l] - ypred[0]) ** 2\n",
    "\n",
    "        ldacvindex[j][k] = CV / 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Find minimum cv location (0, 4, 6, 7, 9) 0.18333333333333332\n",
    "mini = list()\n",
    "minilocate = list()\n",
    "for i in range(10):\n",
    "    mini.append(min(ldacvindex[i]))\n",
    "    minilocate.append(np.argmin(ldacvindex[i]))\n",
    "ldamincombin = xcombination[np.argmin(mini)][minilocate[np.argmin(mini)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% QDA +LOOCV\n",
    "qdacvindex = deepcopy(xcombination)\n",
    "for j in range(10):\n",
    "    for k in range(int(len(xcombination[j]))):\n",
    "\n",
    "        X = xdata1.iloc[:, list(map(int, xcombination[j][k]))]\n",
    "        y = data1.loc[::, \"y\"]\n",
    "        CV = 0\n",
    "        for l in range(300):\n",
    "            qda = QuadraticDiscriminantAnalysis()\n",
    "            Xexclude = X.iloc[chain(range(l), range(l + 1, 300)), ::]\n",
    "            yexclude = y[chain(range(l), range(l + 1, 300))]\n",
    "            yout = X.iloc[l, ::]\n",
    "            ypred = qda.fit(Xexclude.values, yexclude.values).predict(\n",
    "                np.reshape(X.loc[l].to_numpy(), (1, j + 1))\n",
    "            )\n",
    "            CV = CV + (y[l] - ypred[0]) ** 2\n",
    "\n",
    "        qdacvindex[j][k] = CV / 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% . (1, 3, 6, 7, 9) 0.17666666666666667\n",
    "mini = list()\n",
    "minilocate = list()\n",
    "for i in range(10):\n",
    "    mini.append(min(qdacvindex[i]))\n",
    "    minilocate.append(np.argmin(qdacvindex[i]))\n",
    "qdamincombin = xcombination[np.argmin(mini)][minilocate[np.argmin(mini)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% logistic reg. +loocv\n",
    "logcvindex = deepcopy(xcombination)\n",
    "for j in range(10):\n",
    "    for k in range(int(len(xcombination[j]))):\n",
    "        loocv = LeaveOneOut()\n",
    "\n",
    "        X = xdata1.iloc[:, list(map(int, xcombination[j][k]))]\n",
    "        y = data1.loc[::, \"y\"]\n",
    "        CV = cross_val_score(\n",
    "            LogisticRegression(solver=\"lbfgs\", n_jobs=-1),\n",
    "            X,\n",
    "            y,\n",
    "            cv=loocv,\n",
    "            scoring=\"neg_mean_squared_error\",\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        #        CV = 0\n",
    "        #       for l in range(300):\n",
    "\n",
    "        #            Xexclude = X.iloc[chain(range(l), range(l + 1, 300)), ::]\n",
    "        #            yexclude = y[chain(range(l), range(l + 1, 300))]\n",
    "        #            yout = X.iloc[l, ::]\n",
    "        #            ypred = (\n",
    "        #                LogisticRegression()\n",
    "        #                .fit(Xexclude.values, yexclude.values)\n",
    "        #                .predict(np.reshape(X.loc[l].to_numpy(), (1, j + 1)))\n",
    "        #            )\n",
    "        #            CV = CV + (y[l] - ypred[0]) ** 2\n",
    "\n",
    "        logcvindex[j][k] = CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% (0, 3, 6, 7, 9) 0.18333333333333332\n",
    "mini = list()\n",
    "minilocate = list()\n",
    "for i in range(10):\n",
    "    mini.append(min(logcvindex[i]))\n",
    "    minilocate.append(np.argmin(logcvindex[i]))\n",
    "logmincombin = xcombination[np.argmin(mini)][minilocate[np.argmin(mini)]]\n",
    "np.min(mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def plot_data(lda, X, y, y_pred, fig_index):\n",
    "    splot = plt.subplot(1, 3, fig_index)\n",
    "    if fig_index == 1:\n",
    "        plt.title(\"Linear Discriminant Analysis\", fontsize=20)\n",
    "    elif fig_index == 2:\n",
    "        plt.title(\"Quadratic Discriminant Analysis\", fontsize=20)\n",
    "    elif fig_index == 3:\n",
    "        plt.title(\"Logistic regression Analysis\", fontsize=20)\n",
    "    tp = y == y_pred  # True Positive\n",
    "    tp0, tp1 = tp[y == 0], tp[y == 1]\n",
    "    X0, X1 = X[y == 0], X[y == 1]\n",
    "    X0_tp, X0_fp = X0[tp0], X0[~tp0]\n",
    "    X1_tp, X1_fp = X1[tp1], X1[~tp1]\n",
    "\n",
    "    # class 0: dots\n",
    "    plt.scatter(X0_tp[:, 0], X0_tp[:, 1], marker=\".\", color=\"red\")\n",
    "    plt.scatter(X0_fp[:, 0], X0_fp[:, 1], marker=\"x\", s=20, color=\"#990000\")  # dark red\n",
    "\n",
    "    # class 1: dots\n",
    "    plt.scatter(X1_tp[:, 0], X1_tp[:, 1], marker=\".\", color=\"blue\")\n",
    "    plt.scatter(\n",
    "        X1_fp[:, 0], X1_fp[:, 1], marker=\"x\", s=20, color=\"#000099\"\n",
    "    )  # dark blue\n",
    "\n",
    "    return splot\n",
    "\n",
    "\n",
    "def plot_ellipse(splot, mean, cov, color):\n",
    "    v, w = linalg.eigh(cov)\n",
    "    u = w[0] / linalg.norm(w[0])\n",
    "    angle = np.arctan(u[1] / u[0])\n",
    "    angle = 180 * angle / np.pi  # convert to degrees\n",
    "    ell = mpl.patches.Ellipse(\n",
    "        mean,\n",
    "        2 * v[0] ** 0.5,\n",
    "        2 * v[1] ** 0.5,\n",
    "        180 + angle,\n",
    "        facecolor=color,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ell.set_clip_box(splot.bbox)\n",
    "    ell.set_alpha(0.2)\n",
    "    splot.add_artist(ell)\n",
    "\n",
    "\n",
    "def plot_lda_cov(lda, splot):\n",
    "    plot_ellipse(splot, lda.means_[0], lda.covariance_, \"red\")\n",
    "    plot_ellipse(splot, lda.means_[1], lda.covariance_, \"blue\")\n",
    "\n",
    "\n",
    "def plot_qda_cov(qda, splot):\n",
    "    plot_ellipse(splot, qda.means_[0], qda.covariance_[0], \"red\")\n",
    "    plot_ellipse(splot, qda.means_[1], qda.covariance_[1], \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "X = xdata1.iloc[:, list(ldamincombin)].values\n",
    "Xqda = xdata1.iloc[:, list(qdamincombin)].values\n",
    "Xlogit = xdata1.iloc[:, list(logmincombin)].values\n",
    "# for i, (X, y) in enumerate([(X,y)]):\n",
    "# Linear Discriminant Analysis\n",
    "logregress = LogisticRegression(n_jobs=-1)\n",
    "y_pred = logregress.fit(Xlogit, y).predict(Xlogit)\n",
    "splot = plot_data(lda, Xlogit, y, y_pred, fig_index=3)  # 2 * i + 1)\n",
    "\n",
    "plt.xlabel(\"x1\", fontsize=20)\n",
    "plt.ylabel(\"x4\", fontsize=20)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% confusionmatrix plot\n",
    "def confusionmatrixplot(qdaconfusionmatrix):\n",
    "    group_names = [\"True Neg\", \"False Pos\", \"False Neg\", \"True Pos\"]\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in qdaconfusionmatrix.flatten()]\n",
    "    group_percentages = [\n",
    "        \"{0:.2%}\".format(value)\n",
    "        for value in qdaconfusionmatrix.flatten() / np.sum(qdaconfusionmatrix)\n",
    "    ]\n",
    "    labels = [\n",
    "        f\"{v1}\\n{v2}\\n{v3}\"\n",
    "        for v1, v2, v3 in zip(group_names, group_counts, group_percentages)\n",
    "    ]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "    ax = sns.heatmap(qdaconfusionmatrix, annot=labels, fmt=\"\", cmap=\"Blues\")\n",
    "    ax.set_title(\"Seaborn Confusion Matrix with labels\\n\\n\")\n",
    "    ax.set_xlabel(\"\\nPredicted Values\")\n",
    "    ax.set_ylabel(\"Actual Values \")\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels([\"False\", \"True\"])\n",
    "    ax.yaxis.set_ticklabels([\"False\", \"True\"])\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% lda confusion\n",
    "lday_pred = lda.fit(X, y).predict(X)\n",
    "ldaconfusionmatrix = confusion_matrix(y, lday_pred)\n",
    "\n",
    "print(\"confusion_matrix: \", ldaconfusionmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% qda confusion\n",
    "qday_pred = qda.fit(Xqda, y).predict(Xqda)\n",
    "qdaconfusionmatrix = confusion_matrix(y, qday_pred)\n",
    "print(\"confusion_matrix: \", qdaconfusionmatrix)\n",
    "confusionmatrixplot(qdaconfusionmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% log confusion\n",
    "log_pred = logregress.fit(Xlogit, y).predict(Xlogit)\n",
    "logconfusionmatrix = confusion_matrix(y, log_pred)\n",
    "print(\"confusion_matrix: \", qdaconfusionmatrix)\n",
    "\n",
    "confusionmatrixplot(logconfusionmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% caculate FDR...\n",
    "confusion = logconfusionmatrix\n",
    "TN = confusion[0][0]\n",
    "FN = confusion[1][0]\n",
    "TP = confusion[1][1]\n",
    "FP = confusion[0][1]\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP / (TP + FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN / (TN + FP)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP / (TP + FP)\n",
    "# Negative predictive value\n",
    "NPV = TN / (TN + FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP / (FP + TN)\n",
    "# False negative rate\n",
    "FNR = FN / (TP + FN)\n",
    "# False discovery rate\n",
    "FDR = FP / (TP + FP)\n",
    "print(FDR)\n",
    "# Overall accuracy\n",
    "ACC = (TP + TN) / (TP + FP + FN + TN)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
